{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies installing and environment initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!nbstripout --install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General environment initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def is_gpu_available():\n",
    "    return tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU is{' ' if tf.config.list_physical_devices('GPU') else ' not '}available on the device\")\n",
    "\n",
    "IMAGES = 7400\n",
    "API_KEY = \"24844585-de839c0e13ca422a989916f16\"\n",
    "WORK_DIR = \"./drive/MyDrive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run following cell to set up in Google Colab environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount(\"./drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run following cell to set up in local environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support function initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread\n",
    "from matplotlib.axes import Axes\n",
    "from random import sample\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def remove_axis(plt: Axes):\n",
    "    plt.axes.xaxis.set_visible(False)\n",
    "    plt.axes.yaxis.set_visible(False)\n",
    "\n",
    "def print_images_line(*images: Image):\n",
    "    fig, axes = subplots(1, len(images), figsize=(15, 15))\n",
    "    for ind, ax in enumerate(axes):\n",
    "        remove_axis(ax)\n",
    "        ax.imshow(images[ind])\n",
    "    display(fig)\n",
    "    close()\n",
    "\n",
    "def print_random_images(images: [Image], num: int = 5):\n",
    "    print_images_line(*[image for image in sample(images, num)])\n",
    "\n",
    "def print_images_from_dir(path: str, num: int = 5):\n",
    "    print_images_line(*[imread(image) for image in sample(listdir(f\"{WORK_DIR}/{path}\"), num)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Use following links to access image sets:\n",
    "Random images: `https://pixabay.com/api/?key={{YOUR_API_KEY}}&image_type=photo&q={{WORD}}&per_page=100&page={{PAGE_NUMBER}}`, where:\n",
    "* `YOUR_API_KEY` is api key, available [here](https://pixabay.com/api/docs) after signing in Pixabay.\n",
    "* `WORD` is a word, that will be used as seed to retrieve pictures.\n",
    "* `PAGE_NUMBER` is a number of page.\n",
    "\n",
    "Plant images available [here](https://www.inaturalist.org/observations/export) after signing in iNaturalist.\n",
    "Use this request `has[]=photos&quality_grade=any&identifications=any&iconic_taxa[]=Plantae&projects[]=leningrad-oblast-flora` to retrieve different plant images.\n",
    "Use this request `has[]=photos&quality_grade=any&identifications=any&iconic_taxa[]=Plantae&taxon_id=499936` to retrieve hogweed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "931948467e3340a8836c2d58de123dd7",
      "06e6ba1fef1e4e14879779f80dddf867",
      "1db4c1d919704990af351d3bd87dd44a",
      "f598d4a182dc40c0a8131807226bfa26",
      "757e6a3d4f8444a78aaced9fe07ae698",
      "da0fddfdee95440895f16b77a270c113",
      "5de3129d17db47fb81941e66bc5f1eaf",
      "7c39c07c6ae04da59549213cb9d07a56",
      "6ebe9fb81ae946ef9f5dc7c3284541b5",
      "89fb516d640a484bae75acba0a8c182d",
      "9783ba48dcda4072b872c0f148e3e0e0",
      "a18045c06a1449759ab994bf7e0c4345",
      "0699a43220e64f4db3aad06bae2f7a25",
      "67c97746213244f89ea7228f224a2f54",
      "c67e7856bb304c94951d3e90c4a5cb0f",
      "5423ecbb28894bd4adddc0138e18209c",
      "34d79de41d6c42adbd7d0a35e674b041",
      "9b7014d6a9364a4b929d172fbdea6b08",
      "9d9ea3df08914623ad7b6511193566cc",
      "5035f54bc0704b20b70ad66fac826758",
      "6879a8ccbd7d417798415542eea6ac53",
      "fa84a18538e04ba08d5e8e8e0c4ed08b",
      "c692cff310ab4171b67416bacb16979b",
      "6f0f362b873c4580978e82d10338db7a",
      "09dfcabb216e4a6396c84f30c5b45e1b",
      "90d248ef2ebf49448af505d61da085af",
      "9bff6923ab1f40d9ae96f0f2e2d111c7",
      "dd38358974884d15a8f7db4375808f43",
      "132d410fb5474090845fada1d60c07d0",
      "7d5f8071d6d240a9a90d4ff185ae76db",
      "e3e5278fbda44e5ab1ba4ebb818ffb56",
      "6e7f0b7d198a4ae78eeae79758a364d7",
      "0a7a4ad9717a4900b7896b2d919ca6f9"
     ]
    },
    "id": "jIskVGQaSDlD",
    "outputId": "0b3449e5-50a8-4984-8b41-f6b20bd0b0fa"
   },
   "outputs": [],
   "source": [
    "from os import makedirs, listdir, remove, system\n",
    "from shutil import rmtree, move\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from pandas import read_csv\n",
    "from requests import get\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "def clear_path(path: str) -> str:\n",
    "  rmtree(path, ignore_errors=True)\n",
    "  makedirs(path)\n",
    "  return path\n",
    "\n",
    "def split_set(dir):\n",
    "  only_set = listdir(f\"./drive/MyDrive/Hogweb/train/{dir}\")\n",
    "  train_set, test_set = random_split(only_set, [int(0.8 * len(only_set)), int(0.2 * len(only_set))])\n",
    "  for file in test_set:\n",
    "    move(f\"./drive/MyDrive/Hogweb/train/{dir}/{file}\", f\"./drive/MyDrive/Hogweb/test/{dir}/{file}\")\n",
    "\n",
    "\n",
    "print(f\"Train set should contain {IMAGES} hogweed and {IMAGES} other plants images, should also contain {IMAGES} miscellaneous images\")\n",
    "\n",
    "print(\"Preparing 'train' directory\")\n",
    "clear_path(\"./drive/MyDrive/Hogweb/train/hogweed\")\n",
    "clear_path(\"./drive/MyDrive/Hogweb/train/cetera\")\n",
    "clear_path(\"./drive/MyDrive/Hogweb/train/other\")\n",
    "\n",
    "frame = read_csv(\"./drive/MyDrive/Hogweb/hogweed.csv\")\n",
    "\n",
    "print(f\"Downloading hogweed images from iNaturalist ({IMAGES})\")\n",
    "for index, url in zip(trange(IMAGES, desc=\"Downloading\", unit=\"img\"), frame[\"image_url\"].sample(IMAGES)):\n",
    "  with open(f\"./drive/MyDrive/Hogweb/train/hogweed/img{index}.jpg\", \"wb\") as f:\n",
    "    f.write(get(url).content)\n",
    "\n",
    "print(\"iNaturalist dataset hogweed photo samples:\")\n",
    "print_images_from_dir(\"./drive/MyDrive/Hogweb/train/hogweed\")\n",
    "\n",
    "frame = read_csv(\"./drive/MyDrive/Hogweb/regional.csv\")\n",
    "\n",
    "print(f\"Downloading cetera images from iNaturalist ({IMAGES})\")\n",
    "for index, url in zip(trange(IMAGES, desc=\"Downloading\", unit=\"img\"), frame[frame[\"scientific_name\"] != \"Heracleum sosnowskyi\"][\"image_url\"].sample(IMAGES)):\n",
    "  with open(f\"./drive/MyDrive/Hogweb/train/cetera/img{index}.jpg\", \"wb\") as f:\n",
    "    f.write(get(url).content)\n",
    "\n",
    "print(\"iNaturalist dataset other plants photo samples:\")\n",
    "print_images_from_dir(\"./drive/MyDrive/Hogweb/train/cetera\")\n",
    "\n",
    "print(f\"Downloading other train images from Pixabay ({IMAGES})\")\n",
    "urls = []\n",
    "words = [\"emotion\", \"television\", \"mall\", \"science\", \"addition\", \"analyst\", \"manufacturer\", \"song\", \"cheek\", \"flight\", \"aspect\", \"profession\", \"payment\", \"president\", \"preparation\", \"love\", \"climate\", \"desk\", \"security\", \"storage\"]\n",
    "for word in words:\n",
    "  for i in range(5):\n",
    "    urls += list(map(lambda obj: obj[\"webformatURL\"], get(f\"https://pixabay.com/api/?key={API_KEY}&image_type=photo&q={word}&per_page=100&page={i + 1}\").json()[\"hits\"]))\n",
    "for index, url in zip(trange(IMAGES, desc=\"Downloading\", unit=\"img\"), urls):\n",
    "  with open(f\"./drive/MyDrive/Hogweb/train/other/img{index}.jpg\", \"wb\") as f:\n",
    "    f.write(get(url).content)\n",
    "\n",
    "print(\"Pixabay dataset miscellaneous photo samples:\")\n",
    "print_images_from_dir(\"./drive/MyDrive/Hogweb/train/other\")\n",
    "\n",
    "print(\"Preparing 'test' directory\")\n",
    "clear_path(\"./drive/MyDrive/Hogweb/test/hogweed\")\n",
    "clear_path(\"./drive/MyDrive/Hogweb/test/cetera\")\n",
    "clear_path(\"./drive/MyDrive/Hogweb/test/other\")\n",
    "\n",
    "print(\"Filling with hogweed photos\")\n",
    "split_set(\"hogweed\")\n",
    "print(\"Filling with cetera photos\")\n",
    "split_set(\"cetera\")\n",
    "print(\"Filling with other photos\")\n",
    "split_set(\"other\")\n",
    "\n",
    "print(\"Removing ipynb caches\")\n",
    "system(\"rm -rf `find -type d -name .ipynb_checkpoints`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "0_H_k8Xkv1Lv",
    "outputId": "bbe82398-4d27-4f46-df28-144230c35f85"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Resize, ColorJitter, RandomHorizontalFlip, Compose, RandomAffine, ToTensor, Normalize\n",
    "from matplotlib.pyplot import figure, imshow, gca\n",
    "from numpy import hstack, transpose\n",
    "\n",
    "\n",
    "train_transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ColorJitter(hue=0.05, saturation=0.05),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomAffine(25, interpolation=InterpolationMode.BILINEAR),\n",
    "    ToTensor()\n",
    "])\n",
    "test_transform = Compose([Resize((224, 224)), ToTensor()])\n",
    "\n",
    "# iNaturalist train set: ./drive/MyDrive/Hogweb/train\n",
    "# iNaturalist test set: ./drive/MyDrive/Hogweb/test\n",
    "# User test set: ./drive/MyDrive/Hogweed/test\n",
    "\n",
    "train_set = ImageFolder(\"./drive/MyDrive/Hogweb/train\", transform=train_transform)\n",
    "ideal_set = ImageFolder(\"./drive/MyDrive/Hogweb/test\", transform=test_transform)\n",
    "user_set = ImageFolder(\"./drive/MyDrive/Hogweed/test\", transform=test_transform)\n",
    "\n",
    "print(f\"Train set has {len(train_set)} images, test set has {len(ideal_set) + len(user_set)} images; train set will be augmented:\")\n",
    "figure(figsize=(15, 25))\n",
    "remove_axis(gca())\n",
    "imshow(hstack([transpose(hstack([train_set[0][0], train_set[1][0], train_set[2][0], train_set[3][0]]), (1, 2, 0)) for _ in range(6)]))\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "ideal_dataloader = DataLoader(ideal_set, batch_size=32, shuffle=True)\n",
    "user_dataloader = DataLoader(user_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "f4484594730242f1966a701aba563294",
      "9741045a24674180a1d15ff96889d80c",
      "9288a4f9a3ff4540a2d94460e5a1ccc1",
      "2266db66cd4d44c3bc78c509dc1b4559",
      "a1c37a6d1eed49a18519a7d9dc15834d",
      "2be62d2e126143b7a6fd47543709397c",
      "35ab3c70478c447d852b6114b005b6b8",
      "3be3c730f3874089a7daa376b9edf993",
      "a76565a39a384e718ff3d4d06d2b72b5",
      "4acad93d1f8c43b18565c452f6f7957c",
      "f583ff3649d248bbbb4686bf4d084879"
     ]
    },
    "id": "opRLr_aov1Ly",
    "outputId": "2a18f3c1-6fe8-4cf8-a5de-e8c24dd03cfb"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import no_grad\n",
    "from torchvision.models import resnet101\n",
    "from matplotlib.pyplot import subplots, close\n",
    "from IPython.display import display, update_display\n",
    "\n",
    "\n",
    "def redraw_graph(drawable, losses_arr, accuracy_arr):\n",
    "  title = drawable[1].get_title()\n",
    "  x_label = drawable[1].get_xlabel()\n",
    "  y_label = drawable[1].get_ylabel()\n",
    "\n",
    "  drawable[1].cla()\n",
    "  drawable[1].plot(losses_arr, color=\"blue\", label=\"losses\")\n",
    "  drawable[1].scatter(len(losses_arr) - 1, losses_arr[-1], c=\"blue\")\n",
    "  drawable[1].plot(accuracy_arr, color=\"red\", label=\"accuracy\")\n",
    "  drawable[1].scatter(len(accuracy_arr) - 1, accuracy_arr[-1], c=\"red\")\n",
    "\n",
    "  drawable[1].set_ylim(bottom=0)\n",
    "  drawable[1].set_title(title)\n",
    "  drawable[1].set_xlabel(x_label)\n",
    "  drawable[1].set_ylabel(y_label)\n",
    "  drawable[1].legend()\n",
    "  drawable[1].grid(visible=True)\n",
    "\n",
    "  drawable[0].show()\n",
    "  update_display(drawable[0], display_id=drawable[2])\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion, device, losses_arr, accuracy_arr, drawable):\n",
    "  model = model.to(device).train()\n",
    "  total_loss = 0\n",
    "  total_accuracy = 0\n",
    "  with tqdm(desc=\"Training\", unit=\"batch\", total=len(data_loader)) as prbar:\n",
    "    for images, labels in data_loader:\n",
    "      # Move Batch to GPU\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      predicted = model(images)\n",
    "      loss = criterion(predicted, labels)\n",
    "      # Update weights\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      # Update descirption for tqdm\n",
    "      accuracy = (predicted.argmax(1) == labels).float().mean()\n",
    "      prbar.set_description(f\"Loss: {round(loss.item(), 3)}; Accuracy: {round(accuracy.item() * 100, 3)}\")\n",
    "      prbar.update(1)\n",
    "      # Update training graph\n",
    "      losses_arr.append(loss.item())\n",
    "      accuracy_arr.append(accuracy.item())\n",
    "      redraw_graph(drawable, losses_arr, accuracy_arr)\n",
    "      # Updating totals\n",
    "      total_loss += loss.item()\n",
    "      total_accuracy += accuracy.item()\n",
    "    prbar.set_description(f\"Loss: {round(total_loss / len(data_loader), 3)}; Accuracy: {round(total_accuracy / len(data_loader) * 100, 3)}\")\n",
    "  return total_loss / len(data_loader), total_accuracy / len(data_loader)\n",
    "\n",
    "\n",
    "def validate(model, data_loader, criterion, device, losses_arr, accuracy_arr, drawable):\n",
    "  model = model.eval()\n",
    "  total_loss = 0\n",
    "  total_accuracy = 0\n",
    "  with tqdm(desc=\"Testing\", unit=\"batch\", total=len(data_loader)) as prbar:\n",
    "    for images, labels in data_loader:\n",
    "      # Move Batch to GPU\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      predicted = model(images)\n",
    "      loss = criterion(predicted, labels)\n",
    "      # Update descirption for tqdm\n",
    "      accuracy = (predicted.argmax(1) == labels).float().mean()\n",
    "      prbar.set_description(f\"Loss: {round(loss.item(), 3)}; Accuracy: {round(accuracy.item() * 100, 3)}\")\n",
    "      prbar.update(1)\n",
    "      # Update training graph\n",
    "      losses_arr.append(loss.item())\n",
    "      accuracy_arr.append(accuracy.item())\n",
    "      redraw_graph(drawable, losses_arr, accuracy_arr)\n",
    "      # Updating totals\n",
    "      total_loss += loss.item()\n",
    "      total_accuracy += accuracy.item()\n",
    "    prbar.set_description(f\"Loss: {round(total_loss / len(data_loader), 3)}; Accuracy: {round(total_accuracy / len(data_loader) * 100, 3)}\")\n",
    "  return total_loss / len(data_loader), total_accuracy / len(data_loader)\n",
    "\n",
    "def fit(model, epochs, train_data_loader, ideal_data_loader, user_data_loader, optimizer, criterion, device=\"cuda:0\"):\n",
    "    batch_train_losses = []\n",
    "    batch_train_accuracy = []\n",
    "    batch_ideal_losses = []\n",
    "    batch_ideal_accuracy = []\n",
    "    batch_user_losses = []\n",
    "    batch_user_accuracy = []\n",
    "\n",
    "    batch_figure, (batch_train_graph, batch_ideal_graph, batch_user_graph) = subplots(1, 3, figsize=(15, 5))\n",
    "    batch_figure.suptitle(\"Accuracy/Loss graph\")\n",
    "    batch_train_graph.set_title(\"Training\")\n",
    "    batch_ideal_graph.set_title(\"Ideal data testing\")\n",
    "    batch_user_graph.set_title(\"User data testing\")\n",
    "    for graph in (batch_train_graph, batch_ideal_graph, batch_user_graph):\n",
    "      graph.set_xlabel(\"Batches\")\n",
    "      graph.set_ylabel(\"Accuracy/Losses\")\n",
    "      graph.grid(visible=True)\n",
    "    batch_display_id = \"batch_graph\"\n",
    "    display(batch_figure, display_id=batch_display_id)\n",
    "    #close()\n",
    "\n",
    "    epoch_train_losses = []\n",
    "    epoch_train_accuracy = []\n",
    "    epoch_ideal_losses = []\n",
    "    epoch_ideal_accuracy = []\n",
    "    epoch_user_losses = []\n",
    "    epoch_user_accuracy = []\n",
    "\n",
    "    epoch_figure, (epoch_train_graph, epoch_ideal_graph, epoch_user_graph) = subplots(1, 3, figsize=(15, 5))\n",
    "    epoch_figure.suptitle(\"Accuracy/Loss graph\")\n",
    "    epoch_train_graph.set_title(\"Training\")\n",
    "    epoch_ideal_graph.set_title(\"Ideal data testing\")\n",
    "    epoch_user_graph.set_title(\"User data testing\")\n",
    "    for graph in (epoch_train_graph, epoch_ideal_graph, epoch_user_graph):\n",
    "      graph.set_xlabel(\"Epochs\")\n",
    "      graph.set_ylabel(\"Accuracy/Losses\")\n",
    "      graph.grid(visible=True)\n",
    "    epoch_display_id = \"epoch_graph\"\n",
    "    display(epoch_figure, display_id=epoch_display_id)\n",
    "    #close()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      # Train step\n",
    "      print(f\"Train Epoch: {epoch}\")\n",
    "      epoch_loss, epoch_accuracy = train_epoch(model, train_data_loader, optimizer, criterion, device, batch_train_losses, batch_train_accuracy, (batch_figure, batch_train_graph, batch_display_id))\n",
    "      epoch_train_losses.append(epoch_loss)\n",
    "      epoch_train_accuracy.append(epoch_accuracy)\n",
    "      redraw_graph((epoch_figure, epoch_train_graph, epoch_display_id), epoch_train_losses, epoch_train_accuracy)\n",
    "      # Test step\n",
    "      with no_grad():\n",
    "        print(f\"Ideal testing Epoch: {epoch}\")\n",
    "        ideal_loss, ideal_accuracy = validate(model, ideal_data_loader, criterion, device, batch_ideal_losses, batch_ideal_accuracy, (batch_figure, batch_ideal_graph, batch_display_id))\n",
    "        epoch_ideal_losses.append(ideal_loss)\n",
    "        epoch_ideal_accuracy.append(ideal_accuracy)\n",
    "        redraw_graph((epoch_figure, epoch_ideal_graph, epoch_display_id), epoch_ideal_losses, epoch_ideal_accuracy)\n",
    "        print(f\"User testing Epoch: {epoch}\")\n",
    "        user_loss, user_accuracy = validate(model, user_data_loader, criterion, device, batch_user_losses, batch_user_accuracy, (batch_figure, batch_user_graph, batch_display_id))\n",
    "        epoch_user_losses.append(user_loss)\n",
    "        epoch_user_accuracy.append(user_accuracy)\n",
    "        redraw_graph((epoch_figure, epoch_user_graph, epoch_display_id), epoch_user_losses, epoch_user_accuracy)\n",
    "\n",
    "\n",
    "model = resnet101(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = Linear(2048, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489,
     "referenced_widgets": [
      "8e1d4e64291a4dca9f0979b302002fb3",
      "607c2ae95b2e4a0a97dd0fce5722e26a",
      "b15f22b1ab464dd9885a3fce2aa1f835",
      "6bff9a3c8c2f472784e66fad18eadc4f",
      "6c8cfc87babb42fda1eb5c4603eb31a0",
      "14bb358f8d03486b94fd19d4f2c7abf9",
      "fbfb73783c504724858c4f7865e2d738",
      "c621edf99e9542f69f428ded8f6216a3",
      "dffc4f22494045f5a450e9358758ecf5",
      "6fc72c209d114e09a5a1ad4da478e462",
      "2797e91d46594855a6bb2a81c373f607",
      "acc18e416c7c4b168ccf0af3c4e8dc9e",
      "442e56e40a614c9eada788a2bff3db8c",
      "a19f7115b59c46b5a8a8a36d3ed6190f",
      "e986d0987a3c4565925fd8df52ccc3e4",
      "c9e5c91d6b8944569dc65a0a9900ce5f",
      "21674a2db4ee4dadbe1d48b1ff4f7e8d",
      "bfcea49cefe84937b82c80d81d30e2ef",
      "3905b84a48334b5dadbee1c1c8f54d7d",
      "7d34aed08231491d9a288f89b58ab0ff",
      "27c4ecc0821647eb919cb1e37991b540",
      "b87a6d29d1824745a8d221d6556eda52"
     ]
    },
    "id": "b_s-imA5v1L1",
    "outputId": "cbf17988-eda4-4a5c-c25f-3827910138b1"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.cuda import is_available\n",
    "from torch import save\n",
    "\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.fc.parameters(), 1e-4)\n",
    "fit(model, 8, train_dataloader, ideal_dataloader, user_dataloader, optimizer, criterion, \"cuda:0\" if is_available() else \"cpu\")\n",
    "save(model, \"./drive/MyDrive/Hogweed/model1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "3Dhb_etb4lPx",
    "outputId": "21cdf2d3-1842-49b1-bc1c-33deb7f12a43"
   },
   "outputs": [],
   "source": [
    "from shutil import copy2\n",
    "from torch import device, load\n",
    "from torch.cuda import is_available\n",
    "\n",
    "\n",
    "device = device(\"cuda:0\" if is_available() else \"cpu\")\n",
    "model = load(\"./drive/MyDrive/Hogweed/model.pth\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cifGFUyVv1L2",
    "outputId": "9483be1b-febe-4506-b194-a44c5d5d18df",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import no_grad, unsqueeze\n",
    "from torch.nn.functional import softmax\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Resize, Compose, ToTensor\n",
    "\n",
    "\n",
    "def predict(file):  \n",
    "  # Set model to evaluate mode\n",
    "  model.eval()   \n",
    "  \n",
    "  transform = Compose([Resize((224, 224)), ToTensor()])\n",
    "  image = Image.open(file).convert('RGB')\n",
    "  prep = transform(image)\n",
    "  batch = unsqueeze(prep, 0)\n",
    "\n",
    "  with no_grad():\n",
    "    perc = softmax(model(batch), dim=1)\n",
    "  return perc\n",
    "\n",
    "print(train_set.classes)\n",
    "lst = sorted(listdir(\"./drive/MyDrive/Hogweed/test/hogweed\"))\n",
    "for img in lst:\n",
    "  print(f\"{img}: {predict(f'./drive/MyDrive/Hogweed/test/hogweed/{img}')}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
