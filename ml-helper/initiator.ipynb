{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies installing and environment initialization:\n",
    "Run following code in console, not in jupyter server; then launch server using fresh-created virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --user pipenv\n",
    "!pipenv install --skip-lock\n",
    "!nbstripout --install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General environment initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def is_gpu_available():\n",
    "    return tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU is{' ' if tf.config.list_physical_devices('GPU') else ' not '}available on the device\")\n",
    "\n",
    "IMAGES = 7400\n",
    "API_KEY = \"24844585-de839c0e13ca422a989916f16\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Run following cell to set up in Google Colab environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount(\"./drive\")\n",
    "WORK_DIR = \"./drive/MyDrive/Hogweb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run following cell to set up in local environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "WORK_DIR = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support function initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread, subplots, close\n",
    "from matplotlib.axes import Axes\n",
    "from random import sample\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def remove_axis(plt: Axes):\n",
    "    plt.axes.xaxis.set_visible(False)\n",
    "    plt.axes.yaxis.set_visible(False)\n",
    "\n",
    "def print_images_line(*images: Image):\n",
    "    fig, axes = subplots(1, len(images), figsize=(15, 15))\n",
    "    for ind, ax in enumerate(axes):\n",
    "        remove_axis(ax)\n",
    "        ax.imshow(images[ind])\n",
    "    display(fig)\n",
    "    close()\n",
    "\n",
    "def print_random_images(images: [Image], num: int = 5):\n",
    "    print_images_line(*[image for image in sample(images, num)])\n",
    "\n",
    "def print_images_from_dir(path: str, num: int = 5):\n",
    "    print_images_line(*[imread(f\"{path}/{image}\") for image in sample(listdir(path), num)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Use following links to access image sets:\n",
    "Random images available [here](https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv).\n",
    "It is a validation set of [OpenImages](https://storage.googleapis.com/openimages/web/index.html) dataset, it will be enough for our purposes.\n",
    "\n",
    "Plant images available [here](https://www.inaturalist.org/observations/export) after signing in iNaturalist.\n",
    "* Use this request `has[]=photos&quality_grade=any&identifications=any&iconic_taxa[]=Plantae&projects[]=leningrad-oblast-flora` to retrieve different plant images.\n",
    "* Use this request `has[]=photos&quality_grade=any&identifications=any&iconic_taxa[]=Plantae&taxon_id=499936` to retrieve hogweed images.\n",
    "\n",
    "Please make sure `.csv` files received using given requests and links are placed in `./datasets` directory before running the following cell, making sure:\n",
    "* The random image dataset file name should be `random.csv`.\n",
    "* The hogweed image dataset file name should be `hogweed.csv`.\n",
    "* The other plants image dataset file name should be `regional.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "931948467e3340a8836c2d58de123dd7",
      "06e6ba1fef1e4e14879779f80dddf867",
      "1db4c1d919704990af351d3bd87dd44a",
      "f598d4a182dc40c0a8131807226bfa26",
      "757e6a3d4f8444a78aaced9fe07ae698",
      "da0fddfdee95440895f16b77a270c113",
      "5de3129d17db47fb81941e66bc5f1eaf",
      "7c39c07c6ae04da59549213cb9d07a56",
      "6ebe9fb81ae946ef9f5dc7c3284541b5",
      "89fb516d640a484bae75acba0a8c182d",
      "9783ba48dcda4072b872c0f148e3e0e0",
      "a18045c06a1449759ab994bf7e0c4345",
      "0699a43220e64f4db3aad06bae2f7a25",
      "67c97746213244f89ea7228f224a2f54",
      "c67e7856bb304c94951d3e90c4a5cb0f",
      "5423ecbb28894bd4adddc0138e18209c",
      "34d79de41d6c42adbd7d0a35e674b041",
      "9b7014d6a9364a4b929d172fbdea6b08",
      "9d9ea3df08914623ad7b6511193566cc",
      "5035f54bc0704b20b70ad66fac826758",
      "6879a8ccbd7d417798415542eea6ac53",
      "fa84a18538e04ba08d5e8e8e0c4ed08b",
      "c692cff310ab4171b67416bacb16979b",
      "6f0f362b873c4580978e82d10338db7a",
      "09dfcabb216e4a6396c84f30c5b45e1b",
      "90d248ef2ebf49448af505d61da085af",
      "9bff6923ab1f40d9ae96f0f2e2d111c7",
      "dd38358974884d15a8f7db4375808f43",
      "132d410fb5474090845fada1d60c07d0",
      "7d5f8071d6d240a9a90d4ff185ae76db",
      "e3e5278fbda44e5ab1ba4ebb818ffb56",
      "6e7f0b7d198a4ae78eeae79758a364d7",
      "0a7a4ad9717a4900b7896b2d919ca6f9"
     ]
    },
    "id": "jIskVGQaSDlD",
    "outputId": "0b3449e5-50a8-4984-8b41-f6b20bd0b0fa",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from imagehash import average_hash\n",
    "from os import makedirs, system\n",
    "from tqdm.notebook import tqdm\n",
    "from pandas import read_csv\n",
    "from shutil import rmtree\n",
    "from requests import get\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def clear_path(path: str) -> str:\n",
    "    rmtree(path, ignore_errors=True)\n",
    "    makedirs(path)\n",
    "    return path\n",
    "\n",
    "def download_and_save(img_source: str, img_type: str, count: int, source: [str]):\n",
    "    print(f\"Downloading {img_type} images from {img_source}\")\n",
    "    img_hashes = set()\n",
    "    img_code = 0\n",
    "\n",
    "    with tqdm(total=count, desc=\"Downloading\", unit=\"img\") as bar:\n",
    "        while len(img_hashes) < count:\n",
    "            if img_code >= len(source):\n",
    "                raise RuntimeError(f\"The source set contains only {len(source)} elements, {img_code}th was requested!\")\n",
    "            else:\n",
    "                try:\n",
    "                    img_content = Image.open(BytesIO(get(source[img_code]).content))\n",
    "                    img_hash = average_hash(img_content)\n",
    "                    if img_hash not in img_hashes:\n",
    "                        img_hashes.add(img_hash)\n",
    "                        img_content.save(f\"{WORK_DIR}/{img_type}/img{img_code}.jpg\")\n",
    "                        bar.update()\n",
    "                finally:\n",
    "                    img_code += 1\n",
    "                    continue\n",
    "\n",
    "    print(f\"Downloaded {img_code + 1} images finished, {img_code + 1 - count} collisions found\")\n",
    "    print(f\"{img_source} dataset {img_type} image samples:\")\n",
    "    print_images_from_dir(f\"{WORK_DIR}/{img_type}\")\n",
    "\n",
    "\n",
    "print(f\"Train set should contain hogweed, cetera and other images, {IMAGES} of each kind\")\n",
    "\n",
    "print(\"Preparing directories\")\n",
    "clear_path(f\"{WORK_DIR}/hogweed\")\n",
    "clear_path(f\"{WORK_DIR}/cetera\")\n",
    "clear_path(f\"{WORK_DIR}/other\")\n",
    "\n",
    "frame = read_csv(\"./datasets/hogweed.csv\")\n",
    "download_and_save(\"iNaturalist\", \"hogweed\", IMAGES, frame[\"image_url\"])\n",
    "\n",
    "frame = read_csv(\"./datasets/regional.csv\")\n",
    "download_and_save(\"iNaturalist\", \"cetera\", IMAGES, frame[frame[\"scientific_name\"] != \"Heracleum sosnowskyi\"][\"image_url\"])\n",
    "\n",
    "frame = read_csv(\"./datasets/random.csv\")\n",
    "download_and_save(\"UnSplash\", \"other\", IMAGES, frame[\"OriginalURL\"])\n",
    "\n",
    "print(\"Removing ipynb caches\")\n",
    "system(\"rm -rf `find -type d -name .ipynb_checkpoints`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "0_H_k8Xkv1Lv",
    "outputId": "bbe82398-4d27-4f46-df28-144230c35f85"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Resize, ColorJitter, RandomHorizontalFlip, Compose, RandomAffine, ToTensor, Normalize\n",
    "from matplotlib.pyplot import figure, imshow, gca\n",
    "from numpy import hstack, transpose\n",
    "\n",
    "\n",
    "train_transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ColorJitter(hue=0.05, saturation=0.05),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomAffine(25, interpolation=InterpolationMode.BILINEAR),\n",
    "    ToTensor()\n",
    "])\n",
    "test_transform = Compose([Resize((224, 224)), ToTensor()])\n",
    "\n",
    "# iNaturalist train set: ./drive/MyDrive/Hogweb/train\n",
    "# iNaturalist test set: ./drive/MyDrive/Hogweb/test\n",
    "# User test set: ./drive/MyDrive/Hogweed/test\n",
    "\n",
    "train_set = ImageFolder(\"./drive/MyDrive/Hogweb/train\", transform=train_transform)\n",
    "ideal_set = ImageFolder(\"./drive/MyDrive/Hogweb/test\", transform=test_transform)\n",
    "user_set = ImageFolder(\"./drive/MyDrive/Hogweed/test\", transform=test_transform)\n",
    "\n",
    "print(f\"Train set has {len(train_set)} images, test set has {len(ideal_set) + len(user_set)} images; train set will be augmented:\")\n",
    "figure(figsize=(15, 25))\n",
    "remove_axis(gca())\n",
    "imshow(hstack([transpose(hstack([train_set[0][0], train_set[1][0], train_set[2][0], train_set[3][0]]), (1, 2, 0)) for _ in range(6)]))\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "ideal_dataloader = DataLoader(ideal_set, batch_size=32, shuffle=True)\n",
    "user_dataloader = DataLoader(user_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "f4484594730242f1966a701aba563294",
      "9741045a24674180a1d15ff96889d80c",
      "9288a4f9a3ff4540a2d94460e5a1ccc1",
      "2266db66cd4d44c3bc78c509dc1b4559",
      "a1c37a6d1eed49a18519a7d9dc15834d",
      "2be62d2e126143b7a6fd47543709397c",
      "35ab3c70478c447d852b6114b005b6b8",
      "3be3c730f3874089a7daa376b9edf993",
      "a76565a39a384e718ff3d4d06d2b72b5",
      "4acad93d1f8c43b18565c452f6f7957c",
      "f583ff3649d248bbbb4686bf4d084879"
     ]
    },
    "id": "opRLr_aov1Ly",
    "outputId": "2a18f3c1-6fe8-4cf8-a5de-e8c24dd03cfb"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import no_grad\n",
    "from torchvision.models import resnet101\n",
    "from matplotlib.pyplot import subplots, close\n",
    "from IPython.display import display, update_display\n",
    "\n",
    "\n",
    "def redraw_graph(drawable, losses_arr, accuracy_arr):\n",
    "  title = drawable[1].get_title()\n",
    "  x_label = drawable[1].get_xlabel()\n",
    "  y_label = drawable[1].get_ylabel()\n",
    "\n",
    "  drawable[1].cla()\n",
    "  drawable[1].plot(losses_arr, color=\"blue\", label=\"losses\")\n",
    "  drawable[1].scatter(len(losses_arr) - 1, losses_arr[-1], c=\"blue\")\n",
    "  drawable[1].plot(accuracy_arr, color=\"red\", label=\"accuracy\")\n",
    "  drawable[1].scatter(len(accuracy_arr) - 1, accuracy_arr[-1], c=\"red\")\n",
    "\n",
    "  drawable[1].set_ylim(bottom=0)\n",
    "  drawable[1].set_title(title)\n",
    "  drawable[1].set_xlabel(x_label)\n",
    "  drawable[1].set_ylabel(y_label)\n",
    "  drawable[1].legend()\n",
    "  drawable[1].grid(visible=True)\n",
    "\n",
    "  drawable[0].show()\n",
    "  update_display(drawable[0], display_id=drawable[2])\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion, device, losses_arr, accuracy_arr, drawable):\n",
    "  model = model.to(device).train()\n",
    "  total_loss = 0\n",
    "  total_accuracy = 0\n",
    "  with tqdm(desc=\"Training\", unit=\"batch\", total=len(data_loader)) as prbar:\n",
    "    for images, labels in data_loader:\n",
    "      # Move Batch to GPU\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      predicted = model(images)\n",
    "      loss = criterion(predicted, labels)\n",
    "      # Update weights\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      # Update descirption for tqdm\n",
    "      accuracy = (predicted.argmax(1) == labels).float().mean()\n",
    "      prbar.set_description(f\"Loss: {round(loss.item(), 3)}; Accuracy: {round(accuracy.item() * 100, 3)}\")\n",
    "      prbar.update(1)\n",
    "      # Update training graph\n",
    "      losses_arr.append(loss.item())\n",
    "      accuracy_arr.append(accuracy.item())\n",
    "      redraw_graph(drawable, losses_arr, accuracy_arr)\n",
    "      # Updating totals\n",
    "      total_loss += loss.item()\n",
    "      total_accuracy += accuracy.item()\n",
    "    prbar.set_description(f\"Loss: {round(total_loss / len(data_loader), 3)}; Accuracy: {round(total_accuracy / len(data_loader) * 100, 3)}\")\n",
    "  return total_loss / len(data_loader), total_accuracy / len(data_loader)\n",
    "\n",
    "\n",
    "def validate(model, data_loader, criterion, device, losses_arr, accuracy_arr, drawable):\n",
    "  model = model.eval()\n",
    "  total_loss = 0\n",
    "  total_accuracy = 0\n",
    "  with tqdm(desc=\"Testing\", unit=\"batch\", total=len(data_loader)) as prbar:\n",
    "    for images, labels in data_loader:\n",
    "      # Move Batch to GPU\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      predicted = model(images)\n",
    "      loss = criterion(predicted, labels)\n",
    "      # Update descirption for tqdm\n",
    "      accuracy = (predicted.argmax(1) == labels).float().mean()\n",
    "      prbar.set_description(f\"Loss: {round(loss.item(), 3)}; Accuracy: {round(accuracy.item() * 100, 3)}\")\n",
    "      prbar.update(1)\n",
    "      # Update training graph\n",
    "      losses_arr.append(loss.item())\n",
    "      accuracy_arr.append(accuracy.item())\n",
    "      redraw_graph(drawable, losses_arr, accuracy_arr)\n",
    "      # Updating totals\n",
    "      total_loss += loss.item()\n",
    "      total_accuracy += accuracy.item()\n",
    "    prbar.set_description(f\"Loss: {round(total_loss / len(data_loader), 3)}; Accuracy: {round(total_accuracy / len(data_loader) * 100, 3)}\")\n",
    "  return total_loss / len(data_loader), total_accuracy / len(data_loader)\n",
    "\n",
    "def fit(model, epochs, train_data_loader, ideal_data_loader, user_data_loader, optimizer, criterion, device=\"cuda:0\"):\n",
    "    batch_train_losses = []\n",
    "    batch_train_accuracy = []\n",
    "    batch_ideal_losses = []\n",
    "    batch_ideal_accuracy = []\n",
    "    batch_user_losses = []\n",
    "    batch_user_accuracy = []\n",
    "\n",
    "    batch_figure, (batch_train_graph, batch_ideal_graph, batch_user_graph) = subplots(1, 3, figsize=(15, 5))\n",
    "    batch_figure.suptitle(\"Accuracy/Loss graph\")\n",
    "    batch_train_graph.set_title(\"Training\")\n",
    "    batch_ideal_graph.set_title(\"Ideal data testing\")\n",
    "    batch_user_graph.set_title(\"User data testing\")\n",
    "    for graph in (batch_train_graph, batch_ideal_graph, batch_user_graph):\n",
    "      graph.set_xlabel(\"Batches\")\n",
    "      graph.set_ylabel(\"Accuracy/Losses\")\n",
    "      graph.grid(visible=True)\n",
    "    batch_display_id = \"batch_graph\"\n",
    "    display(batch_figure, display_id=batch_display_id)\n",
    "    #close()\n",
    "\n",
    "    epoch_train_losses = []\n",
    "    epoch_train_accuracy = []\n",
    "    epoch_ideal_losses = []\n",
    "    epoch_ideal_accuracy = []\n",
    "    epoch_user_losses = []\n",
    "    epoch_user_accuracy = []\n",
    "\n",
    "    epoch_figure, (epoch_train_graph, epoch_ideal_graph, epoch_user_graph) = subplots(1, 3, figsize=(15, 5))\n",
    "    epoch_figure.suptitle(\"Accuracy/Loss graph\")\n",
    "    epoch_train_graph.set_title(\"Training\")\n",
    "    epoch_ideal_graph.set_title(\"Ideal data testing\")\n",
    "    epoch_user_graph.set_title(\"User data testing\")\n",
    "    for graph in (epoch_train_graph, epoch_ideal_graph, epoch_user_graph):\n",
    "      graph.set_xlabel(\"Epochs\")\n",
    "      graph.set_ylabel(\"Accuracy/Losses\")\n",
    "      graph.grid(visible=True)\n",
    "    epoch_display_id = \"epoch_graph\"\n",
    "    display(epoch_figure, display_id=epoch_display_id)\n",
    "    #close()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      # Train step\n",
    "      print(f\"Train Epoch: {epoch}\")\n",
    "      epoch_loss, epoch_accuracy = train_epoch(model, train_data_loader, optimizer, criterion, device, batch_train_losses, batch_train_accuracy, (batch_figure, batch_train_graph, batch_display_id))\n",
    "      epoch_train_losses.append(epoch_loss)\n",
    "      epoch_train_accuracy.append(epoch_accuracy)\n",
    "      redraw_graph((epoch_figure, epoch_train_graph, epoch_display_id), epoch_train_losses, epoch_train_accuracy)\n",
    "      # Test step\n",
    "      with no_grad():\n",
    "        print(f\"Ideal testing Epoch: {epoch}\")\n",
    "        ideal_loss, ideal_accuracy = validate(model, ideal_data_loader, criterion, device, batch_ideal_losses, batch_ideal_accuracy, (batch_figure, batch_ideal_graph, batch_display_id))\n",
    "        epoch_ideal_losses.append(ideal_loss)\n",
    "        epoch_ideal_accuracy.append(ideal_accuracy)\n",
    "        redraw_graph((epoch_figure, epoch_ideal_graph, epoch_display_id), epoch_ideal_losses, epoch_ideal_accuracy)\n",
    "        print(f\"User testing Epoch: {epoch}\")\n",
    "        user_loss, user_accuracy = validate(model, user_data_loader, criterion, device, batch_user_losses, batch_user_accuracy, (batch_figure, batch_user_graph, batch_display_id))\n",
    "        epoch_user_losses.append(user_loss)\n",
    "        epoch_user_accuracy.append(user_accuracy)\n",
    "        redraw_graph((epoch_figure, epoch_user_graph, epoch_display_id), epoch_user_losses, epoch_user_accuracy)\n",
    "\n",
    "\n",
    "model = resnet101(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = Linear(2048, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489,
     "referenced_widgets": [
      "8e1d4e64291a4dca9f0979b302002fb3",
      "607c2ae95b2e4a0a97dd0fce5722e26a",
      "b15f22b1ab464dd9885a3fce2aa1f835",
      "6bff9a3c8c2f472784e66fad18eadc4f",
      "6c8cfc87babb42fda1eb5c4603eb31a0",
      "14bb358f8d03486b94fd19d4f2c7abf9",
      "fbfb73783c504724858c4f7865e2d738",
      "c621edf99e9542f69f428ded8f6216a3",
      "dffc4f22494045f5a450e9358758ecf5",
      "6fc72c209d114e09a5a1ad4da478e462",
      "2797e91d46594855a6bb2a81c373f607",
      "acc18e416c7c4b168ccf0af3c4e8dc9e",
      "442e56e40a614c9eada788a2bff3db8c",
      "a19f7115b59c46b5a8a8a36d3ed6190f",
      "e986d0987a3c4565925fd8df52ccc3e4",
      "c9e5c91d6b8944569dc65a0a9900ce5f",
      "21674a2db4ee4dadbe1d48b1ff4f7e8d",
      "bfcea49cefe84937b82c80d81d30e2ef",
      "3905b84a48334b5dadbee1c1c8f54d7d",
      "7d34aed08231491d9a288f89b58ab0ff",
      "27c4ecc0821647eb919cb1e37991b540",
      "b87a6d29d1824745a8d221d6556eda52"
     ]
    },
    "id": "b_s-imA5v1L1",
    "outputId": "cbf17988-eda4-4a5c-c25f-3827910138b1"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.cuda import is_available\n",
    "from torch import save\n",
    "\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.fc.parameters(), 1e-4)\n",
    "fit(model, 8, train_dataloader, ideal_dataloader, user_dataloader, optimizer, criterion, \"cuda:0\" if is_available() else \"cpu\")\n",
    "save(model, \"./drive/MyDrive/Hogweed/model1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "3Dhb_etb4lPx",
    "outputId": "21cdf2d3-1842-49b1-bc1c-33deb7f12a43"
   },
   "outputs": [],
   "source": [
    "from shutil import copy2\n",
    "from torch import device, load\n",
    "from torch.cuda import is_available\n",
    "\n",
    "\n",
    "device = device(\"cuda:0\" if is_available() else \"cpu\")\n",
    "model = load(\"./drive/MyDrive/Hogweed/model.pth\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cifGFUyVv1L2",
    "outputId": "9483be1b-febe-4506-b194-a44c5d5d18df",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import no_grad, unsqueeze\n",
    "from torch.nn.functional import softmax\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Resize, Compose, ToTensor\n",
    "\n",
    "\n",
    "def predict(file):  \n",
    "  # Set model to evaluate mode\n",
    "  model.eval()   \n",
    "  \n",
    "  transform = Compose([Resize((224, 224)), ToTensor()])\n",
    "  image = Image.open(file).convert('RGB')\n",
    "  prep = transform(image)\n",
    "  batch = unsqueeze(prep, 0)\n",
    "\n",
    "  with no_grad():\n",
    "    perc = softmax(model(batch), dim=1)\n",
    "  return perc\n",
    "\n",
    "print(train_set.classes)\n",
    "lst = sorted(listdir(\"./drive/MyDrive/Hogweed/test/hogweed\"))\n",
    "for img in lst:\n",
    "  print(f\"{img}: {predict(f'./drive/MyDrive/Hogweed/test/hogweed/{img}')}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
