{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies installing and environment initialization:\n",
    "Run following code in console, not in jupyter server; then launch server using fresh-created virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --user pipenv\n",
    "!mkdir venv && python -m pipenv install --skip-lock venv\n",
    "!python -m pipenv shell\n",
    "!nbstripout --install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General environment initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework.config import list_physical_devices\n",
    "from tensorflow.python.platform.test import is_built_with_cuda\n",
    "\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}, built {'with' if is_built_with_cuda() else 'without'} CUDA\")\n",
    "gpu_available = len(list_physical_devices('GPU')) != 0\n",
    "print(f\"GPU is{' ' if gpu_available else ' not '}available on the device\")\n",
    "if not gpu_available:\n",
    "    print(\"Consider following the guide https://www.tensorflow.org/install/gpu for model training\")\n",
    "\n",
    "IMAGES = 7400\n",
    "API_KEY = \"24844585-de839c0e13ca422a989916f16\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (299, 299)\n",
    "\n",
    "INITIAL_EPOCHS = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Run following cell to set up in Google Colab environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount(\"./drive\")\n",
    "IMAGE_DIR = \"./drive/MyDrive/Hogweb\"\n",
    "MODEL_DIR = \"./drive/MyDrive/Hogweed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run following cell to set up in local environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"./data\"\n",
    "MODEL_DIR = \"./model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support function initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread, subplots, close\n",
    "from IPython.display import display\n",
    "from matplotlib.axes import Axes\n",
    "from random import sample\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def remove_axis(plt: Axes):\n",
    "    plt.axes.xaxis.set_visible(False)\n",
    "    plt.axes.yaxis.set_visible(False)\n",
    "\n",
    "def print_images_line(images: [Image]):\n",
    "    fig, axes = subplots(1, len(images), figsize=(15, 15))\n",
    "    for ind, ax in enumerate(axes):\n",
    "        remove_axis(ax)\n",
    "        ax.imshow(images[ind])\n",
    "    display(fig)\n",
    "    close(fig)\n",
    "\n",
    "def print_random_images(images: [Image], num: int = 5):\n",
    "    print_images_line([image for image in sample(images, num)])\n",
    "\n",
    "def print_images_from_dir(path: str, num: int = 5):\n",
    "    print_images_line([imread(f\"{path}/{image}\") for image in sample(listdir(path), num)])\n",
    "\n",
    "def naturalize_urls(urls: list[str]) -> list[str]:\n",
    "    return [url.replace(\"medium\", \"large\") for url in urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Use following links to access image sets:\n",
    "Random images available [here](https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv).\n",
    "It is a validation set of [OpenImages](https://storage.googleapis.com/openimages/web/index.html) dataset, but it contains enough images for hogweed classification.\n",
    "\n",
    "Plant images available [here](https://www.inaturalist.org/observations/export) after signing in iNaturalist.\n",
    "* Use this request `has[]=photos&quality_grade=any&identifications=any&iconic_taxa[]=Plantae&projects[]=leningrad-oblast-flora` to retrieve different plant images.\n",
    "* Use this request `has[]=photos&quality_grade=any&identifications=any&iconic_taxa[]=Plantae&taxon_id=499936` to retrieve hogweed images.\n",
    "\n",
    "Please make sure `.csv` files received using given requests and links are placed in `./datasets` directory before running the following cell, making sure:\n",
    "* The random image dataset file name should be `other.csv`.\n",
    "* The hogweed image dataset file name should be `hogweed.csv`.\n",
    "* The other plants image dataset file name should be `cetera.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "931948467e3340a8836c2d58de123dd7",
      "06e6ba1fef1e4e14879779f80dddf867",
      "1db4c1d919704990af351d3bd87dd44a",
      "f598d4a182dc40c0a8131807226bfa26",
      "757e6a3d4f8444a78aaced9fe07ae698",
      "da0fddfdee95440895f16b77a270c113",
      "5de3129d17db47fb81941e66bc5f1eaf",
      "7c39c07c6ae04da59549213cb9d07a56",
      "6ebe9fb81ae946ef9f5dc7c3284541b5",
      "89fb516d640a484bae75acba0a8c182d",
      "9783ba48dcda4072b872c0f148e3e0e0",
      "a18045c06a1449759ab994bf7e0c4345",
      "0699a43220e64f4db3aad06bae2f7a25",
      "67c97746213244f89ea7228f224a2f54",
      "c67e7856bb304c94951d3e90c4a5cb0f",
      "5423ecbb28894bd4adddc0138e18209c",
      "34d79de41d6c42adbd7d0a35e674b041",
      "9b7014d6a9364a4b929d172fbdea6b08",
      "9d9ea3df08914623ad7b6511193566cc",
      "5035f54bc0704b20b70ad66fac826758",
      "6879a8ccbd7d417798415542eea6ac53",
      "fa84a18538e04ba08d5e8e8e0c4ed08b",
      "c692cff310ab4171b67416bacb16979b",
      "6f0f362b873c4580978e82d10338db7a",
      "09dfcabb216e4a6396c84f30c5b45e1b",
      "90d248ef2ebf49448af505d61da085af",
      "9bff6923ab1f40d9ae96f0f2e2d111c7",
      "dd38358974884d15a8f7db4375808f43",
      "132d410fb5474090845fada1d60c07d0",
      "7d5f8071d6d240a9a90d4ff185ae76db",
      "e3e5278fbda44e5ab1ba4ebb818ffb56",
      "6e7f0b7d198a4ae78eeae79758a364d7",
      "0a7a4ad9717a4900b7896b2d919ca6f9"
     ]
    },
    "id": "jIskVGQaSDlD",
    "outputId": "0b3449e5-50a8-4984-8b41-f6b20bd0b0fa",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from imagehash import average_hash\n",
    "from os import makedirs, system\n",
    "from tqdm.notebook import tqdm\n",
    "from pandas import read_csv\n",
    "from shutil import rmtree\n",
    "from requests import get\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def clear_path(path: str) -> str:\n",
    "    rmtree(path, ignore_errors=True)\n",
    "    makedirs(path)\n",
    "    return path\n",
    "\n",
    "def download_and_save(img_source: str, img_type: str, count: int, source: [str]):\n",
    "    print(f\"Downloading {img_type} images from {img_source}\")\n",
    "    img_hashes = set()\n",
    "    img_code = 0\n",
    "\n",
    "    with tqdm(total=count, desc=\"Downloading\", unit=\"img\") as bar:\n",
    "        while len(img_hashes) < count:\n",
    "            if img_code >= len(source):\n",
    "                raise RuntimeError(f\"The source set contains only {len(source)} elements, {img_code}th was requested!\")\n",
    "            else:\n",
    "                try:\n",
    "                    img_data = Image.open(BytesIO(get(source[img_code]).content))\n",
    "                    img_hash = average_hash(img_data)\n",
    "                    if img_hash not in img_hashes:\n",
    "                        img_hashes.add(img_hash)\n",
    "                        img_data.save(f\"{IMAGE_DIR}/{img_type}/{img_type}{img_code}.jpg\")\n",
    "                        bar.update()\n",
    "                finally:\n",
    "                    img_code += 1\n",
    "                    continue\n",
    "\n",
    "    print(f\"Downloaded {img_code + 1} images finished, {img_code + 1 - count} collisions or wrong images found\")\n",
    "    print(f\"{img_source} dataset {img_type} image samples:\")\n",
    "    print_images_from_dir(f\"{IMAGE_DIR}/{img_type}\")\n",
    "\n",
    "\n",
    "print(f\"Train set should contain hogweed, cetera and other images, {IMAGES} of each kind\")\n",
    "\n",
    "print(\"Preparing directories\")\n",
    "clear_path(f\"{IMAGE_DIR}/hogweed\")\n",
    "clear_path(f\"{IMAGE_DIR}/cetera\")\n",
    "clear_path(f\"{IMAGE_DIR}/other\")\n",
    "\n",
    "frame = read_csv(\"./datasets/hogweed.csv\")\n",
    "frame = frame[frame[\"license\"] != \"CC0\"][\"image_url\"]\n",
    "download_and_save(\"iNaturalist\", \"hogweed\", IMAGES, naturalize_urls(frame.to_list()))\n",
    "\n",
    "frame = read_csv(\"./datasets/cetera.csv\")\n",
    "frame = frame[(frame[\"license\"] != \"CC0\") & (frame[\"scientific_name\"] != \"Heracleum sosnowskyi\")][\"image_url\"]\n",
    "download_and_save(\"iNaturalist\", \"cetera\", IMAGES, naturalize_urls(frame.to_list()))\n",
    "\n",
    "frame = read_csv(\"./datasets/other.csv\")\n",
    "download_and_save(\"UnSplash\", \"other\", IMAGES, frame[\"OriginalURL\"])\n",
    "\n",
    "print(\"Removing ipynb caches\")\n",
    "system(\"rm -rf `find -type d -name .ipynb_checkpoints`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "\n",
    "\n",
    "frame = read_csv(\"./datasets/hogweed.csv\")\n",
    "hogweed_frame = frame[frame[\"license\"] == \"CC0\"].sample(50)[\"image_url\"]\n",
    "frame = read_csv(\"./datasets/cetera.csv\")\n",
    "cetera_frame = frame[(frame[\"scientific_name\"] != \"Heracleum sosnowskyi\") & (frame[\"license\"] == \"CC0\")].sample(50)[\"image_url\"]\n",
    "\n",
    "URLs = naturalize_urls(hogweed_frame.to_list()) + naturalize_urls(cetera_frame.to_list()) + [f\"https://source.unsplash.com/random?sig={num}\" for num in range(50)]\n",
    "classes = (['hogweed'] * 50) + (['cetera'] * 50) + (['other'] * 50)\n",
    "DataFrame(list(zip(classes, URLs)), columns=['class', 'url']).to_csv(path_or_buf=\"./datasets/validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "0_H_k8Xkv1Lv",
    "outputId": "bbe82398-4d27-4f46-df28-144230c35f85"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import RandomFlip, RandomRotation\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.python.data.experimental import cardinality\n",
    "from tensorflow.python.data import AUTOTUNE\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow import expand_dims\n",
    "\n",
    "\n",
    "dataset = image_dataset_from_directory(IMAGE_DIR, shuffle=True, label_mode='categorical', batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
    "batches_num = cardinality(dataset)\n",
    "\n",
    "train_power = batches_num * 9 // 10\n",
    "train_dataset = dataset.take(train_power).prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = dataset.skip(train_power).take(train_power // 9).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "data_augmentation = Sequential([\n",
    "    RandomFlip('horizontal'),\n",
    "    RandomRotation(0.1),\n",
    "    # RandomContrast(0.01)\n",
    "])\n",
    "\n",
    "print(f\"Train set has {cardinality(train_dataset)} batches, test set has {cardinality(test_dataset)} batches; train set will be augmented:\")\n",
    "for i in range(0, 5):\n",
    "    imgs = []\n",
    "    for img, _ in train_dataset.skip(i).take(1):\n",
    "        for j in range(0, 5):\n",
    "            imgs += [data_augmentation(expand_dims(img[0], 0))[0] / 255]\n",
    "    print_images_line(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import preprocess_input, Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "\n",
    "INPUT_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "base_model = Xception(input_shape=INPUT_SHAPE, include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = Input(shape=INPUT_SHAPE, name=\"re_shaper\")\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = GlobalAveragePooling2D(name=\"pooling\")(x)\n",
    "x = Dropout(0.2, name=\"dropout\")(x)\n",
    "outputs = Dense(3, name=\"predictor\")(x)\n",
    "model = Model(inputs, outputs, name=\"hogweed_detector\")\n",
    "\n",
    "# TODO: check learning rate!\n",
    "# TODO: check optimizer!\n",
    "base_learning_rate = 0.001\n",
    "model.compile(optimizer=Adam(learning_rate=base_learning_rate), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import Callback, EarlyStopping\n",
    "from tensorflow.python.data.experimental import cardinality\n",
    "from IPython.display import display, update_display\n",
    "from matplotlib.pyplot import subplots, close\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.batch_train_accuracy = []\n",
    "        self.batch_train_losses = []\n",
    "\n",
    "        self.epoch_train_accuracy = []\n",
    "        self.epoch_train_losses = []\n",
    "        self.epoch_test_accuracy = []\n",
    "        self.epoch_test_losses = []\n",
    "\n",
    "        self.batch_figure, self.batch_train_graph = subplots(1, 1, figsize=(15, 5))\n",
    "        self.batch_figure.suptitle(\"Accuracy/Loss graph\")\n",
    "        self.batch_train_graph.set_title(\"Training\")\n",
    "        self.batch_train_graph.set_xlabel(\"Batches\")\n",
    "        self.batch_train_graph.set_ylabel(\"Accuracy/Losses\")\n",
    "        self.batch_train_graph.grid(visible=True)\n",
    "        self.batch_display_id = \"batch_graph\"\n",
    "        close(self.batch_figure)\n",
    "\n",
    "        self.epoch_figure, (self.epoch_train_graph, self.epoch_test_graph) = subplots(1, 2, figsize=(15, 5))\n",
    "        self.epoch_figure.suptitle(\"Accuracy/Loss graph\")\n",
    "        self.epoch_train_graph.set_title(\"Training\")\n",
    "        self.epoch_test_graph.set_title(\"Testing\")\n",
    "        for graph in (self.epoch_train_graph, self.epoch_test_graph):\n",
    "            graph.set_xlabel(\"Epochs\")\n",
    "            graph.set_ylabel(\"Accuracy/Losses\")\n",
    "            graph.grid(visible=True)\n",
    "        self.epoch_display_id = \"epoch_graph\"\n",
    "        close(self.epoch_figure)\n",
    "\n",
    "        self.epochs_bar = None\n",
    "        self.batches_bar = None\n",
    "\n",
    "    def redraw_graph(self, figure, graph, display_id, losses_arr, accuracy_arr):\n",
    "        title = graph.get_title()\n",
    "        x_label = graph.get_xlabel()\n",
    "        y_label = graph.get_ylabel()\n",
    "\n",
    "        graph.cla()\n",
    "        graph.plot(losses_arr, color='blue', label=\"losses\")\n",
    "        graph.scatter(len(losses_arr) - 1, losses_arr[-1], c='blue')\n",
    "        graph.plot(accuracy_arr, color='red', label=\"accuracy\")\n",
    "        graph.scatter(len(accuracy_arr) - 1, accuracy_arr[-1], c='red')\n",
    "\n",
    "        graph.set_ylim(bottom=0)\n",
    "        graph.set_title(title)\n",
    "        graph.set_xlabel(x_label)\n",
    "        graph.set_ylabel(y_label)\n",
    "        graph.legend()\n",
    "        graph.grid(visible=True)\n",
    "\n",
    "        figure.canvas.draw()\n",
    "        update_display(figure, display_id=display_id)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        display(self.batch_figure, display_id=self.batch_display_id)\n",
    "        display(self.epoch_figure, display_id=self.epoch_display_id)\n",
    "\n",
    "        self.epochs_bar = tqdm(desc=\"Training\", unit=\"epoch\", total=INITIAL_EPOCHS)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.batches_bar = tqdm(desc=\"Training\", unit=\"batch\", total=cardinality(train_dataset).numpy())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch_train_losses.append(logs['loss'])\n",
    "        self.epoch_train_accuracy.append(logs['accuracy'])\n",
    "        self.redraw_graph(self.epoch_figure, self.epoch_train_graph, self.epoch_display_id, self.epoch_train_losses, self.epoch_train_accuracy)\n",
    "\n",
    "        self.epoch_test_losses.append(logs['val_loss'])\n",
    "        self.epoch_test_accuracy.append(logs['val_accuracy'])\n",
    "        self.redraw_graph(self.epoch_figure, self.epoch_test_graph, self.epoch_display_id, self.epoch_test_losses, self.epoch_test_accuracy)\n",
    "\n",
    "        self.batches_bar.set_description(f\"Loss: {round(logs['loss'], 3)}; Accuracy: {round(logs['accuracy'] * 100, 3)}\")\n",
    "        self.batches_bar.close()\n",
    "        self.epochs_bar.update()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_train_losses.append(logs['loss'])\n",
    "        self.batch_train_accuracy.append(logs['accuracy'])\n",
    "        self.redraw_graph(self.batch_figure, self.batch_train_graph, self.batch_display_id, self.batch_train_losses, self.batch_train_accuracy)\n",
    "\n",
    "        self.batches_bar.set_description(f\"Loss: {round(logs['loss'], 3)}; Accuracy: {round(logs['accuracy'] * 100, 3)}\")\n",
    "        self.batches_bar.update()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.epochs_bar.close()\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset, epochs=INITIAL_EPOCHS, validation_data=test_dataset, verbose=0, callbacks=[CustomCallback(), EarlyStopping(patience=3, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "f4484594730242f1966a701aba563294",
      "9741045a24674180a1d15ff96889d80c",
      "9288a4f9a3ff4540a2d94460e5a1ccc1",
      "2266db66cd4d44c3bc78c509dc1b4559",
      "a1c37a6d1eed49a18519a7d9dc15834d",
      "2be62d2e126143b7a6fd47543709397c",
      "35ab3c70478c447d852b6114b005b6b8",
      "3be3c730f3874089a7daa376b9edf993",
      "a76565a39a384e718ff3d4d06d2b72b5",
      "4acad93d1f8c43b18565c452f6f7957c",
      "f583ff3649d248bbbb4686bf4d084879"
     ]
    },
    "id": "opRLr_aov1Ly",
    "outputId": "2a18f3c1-6fe8-4cf8-a5de-e8c24dd03cfb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.lite.python.lite import TFLiteConverter\n",
    "\n",
    "\n",
    "with open(f\"{MODEL_DIR}/detector-{history['accuracy'][-1]}.tflite\", 'wb') as file:\n",
    "    lite_model = tf.lite.TFLiteConverter.from_keras_model(model).convert()\n",
    "    file.write(lite_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
