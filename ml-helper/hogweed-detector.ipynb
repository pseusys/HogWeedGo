{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies installing and environment initialization:\n",
    "Run following code in console, not in jupyter server; then launch server using fresh-created virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install --user pipenv\n",
    "!python3 -m pipenv install --skip-lock\n",
    "!python3 -m pipenv shell\n",
    "!nbstripout --install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General environment initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework.config import list_physical_devices\n",
    "from tensorflow.python.platform.test import is_built_with_cuda\n",
    "\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}, built {'with' if is_built_with_cuda() else 'without'} CUDA\")\n",
    "gpu_available = len(list_physical_devices('GPU')) != 0\n",
    "print(f\"GPU is{' ' if gpu_available else ' not '}available on the device\")\n",
    "if not gpu_available:\n",
    "    print(\"Consider following the guide https://www.tensorflow.org/install/gpu for model training\")\n",
    "\n",
    "IMAGES = 7100\n",
    "IMG_SIZE = (299, 299)\n",
    "CLASS_NAMES = ['hogweed', 'cetera', 'other']\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "INITIAL_EPOCHS = 16\n",
    "FINE_TUNING_EPOCHS = 16\n",
    "EARLY_STOPPING = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run following cell to set up in Google Colab environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount(\"./drive\")\n",
    "IMAGE_DIR = \"./drive/MyDrive/Hogweb\"\n",
    "MODEL_DIR = \"./drive/MyDrive/Hogweed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run following cell to set up in local environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"./data\"\n",
    "MODEL_DIR = \"./models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support functions and classes initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread, subplots, close\n",
    "from IPython.display import display, update_display\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from matplotlib.axes import Axes\n",
    "from tqdm.notebook import tqdm\n",
    "from random import sample\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class LoggingCallback(Callback):\n",
    "    def __init__(self):\n",
    "        def configure_graph(graph, measure: str, activity: str, param: str):\n",
    "            graph.set_title(f\"{measure} {activity} {param}\")\n",
    "            graph.set_xlabel(measure)\n",
    "            graph.set_ylabel(param)\n",
    "            graph.grid(visible=True)\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_train_accuracy = []\n",
    "        self.batch_train_loss = []\n",
    "        self.epoch_train_accuracy = []\n",
    "        self.epoch_train_loss = []\n",
    "        self.epoch_validation_accuracy = []\n",
    "        self.epoch_validation_loss = []\n",
    "\n",
    "        self.figure, (self.batch_train_graph, self.epoch_train_graph, self.epoch_validation_graph) = subplots(3, 1, figsize=(15, 15))\n",
    "\n",
    "        self.figure.suptitle(\"Accuracy/Loss graphs\")\n",
    "        configure_graph(self.batch_train_graph, \"Batch\", \"training\", \"Accuracy and Loss\")\n",
    "        configure_graph(self.epoch_train_graph, \"Epoch\", \"training\", \"Accuracy and Loss\")\n",
    "        configure_graph(self.epoch_validation_graph, \"Epoch\", \"validation\", \"Accuracy and Loss\")\n",
    "\n",
    "        self.figure_display_id = \"figure\"\n",
    "        close(self.figure)\n",
    "\n",
    "        self.epochs_bar = None\n",
    "        self.batches_bar = None\n",
    "\n",
    "    def redraw_graph(self, graph, accuracy_arr, loss_arr):\n",
    "        title = graph.get_title()\n",
    "        x_label = graph.get_xlabel()\n",
    "        y_label = graph.get_ylabel()\n",
    "\n",
    "        graph.cla()\n",
    "        graph.plot(accuracy_arr, color='red', label=\"accuracy\")\n",
    "        graph.scatter(len(accuracy_arr) - 1, accuracy_arr[-1], c='red')\n",
    "        graph.plot(loss_arr, color='blue', label=\"loss\")\n",
    "        graph.scatter(len(loss_arr) - 1, loss_arr[-1], c='blue')\n",
    "\n",
    "        graph.set_ylim(bottom=0)\n",
    "        graph.set_title(title)\n",
    "        graph.set_xlabel(x_label)\n",
    "        graph.set_ylabel(y_label)\n",
    "        graph.legend()\n",
    "        graph.grid(visible=True)\n",
    "\n",
    "        self.figure.canvas.draw()\n",
    "        update_display(self.figure, display_id=self.figure_display_id)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        display(self.figure, display_id=self.figure_display_id)\n",
    "\n",
    "        self.epochs_bar = tqdm(desc=\"Training\", unit=\"epoch\", total=INITIAL_EPOCHS)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.batches_bar = tqdm(desc=\"Training\", unit=\"batch\", total=train_dataset.cardinality().numpy())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch_train_accuracy.append(logs['accuracy'])\n",
    "        self.epoch_train_loss.append(logs['loss'])\n",
    "        self.redraw_graph(self.epoch_train_graph, self.epoch_train_accuracy, self.epoch_train_loss)\n",
    "\n",
    "        self.epoch_validation_accuracy.append(logs['val_accuracy'])\n",
    "        self.epoch_validation_loss.append(logs['val_loss'])\n",
    "        self.redraw_graph(self.epoch_validation_graph, self.epoch_validation_accuracy, self.epoch_validation_loss)\n",
    "\n",
    "        self.batches_bar.set_description(f\"Loss: {round(logs['loss'], 3)}; Accuracy: {round(logs['accuracy'] * 100, 3)}\")\n",
    "        self.batches_bar.close()\n",
    "        self.epochs_bar.update()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_train_accuracy.append(logs['accuracy'])\n",
    "        self.batch_train_loss.append(logs['loss'])\n",
    "        self.redraw_graph(self.batch_train_graph,self.batch_train_accuracy, self.batch_train_loss)\n",
    "\n",
    "        self.batches_bar.set_description(f\"Loss: {round(logs['loss'], 3)}; Accuracy: {round(logs['accuracy'] * 100, 3)}\")\n",
    "        self.batches_bar.update()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.epochs_bar.close()\n",
    "\n",
    "\n",
    "def remove_axis(plt: Axes):\n",
    "    plt.axes.xaxis.set_visible(False)\n",
    "    plt.axes.yaxis.set_visible(False)\n",
    "\n",
    "def print_images_line(images: [Image]):\n",
    "    fig, axes = subplots(1, len(images), figsize=(15, 15))\n",
    "    for ind, ax in enumerate(axes):\n",
    "        remove_axis(ax)\n",
    "        ax.imshow(images[ind])\n",
    "    display(fig)\n",
    "    close(fig)\n",
    "\n",
    "def print_random_images(images: [Image], num: int = 5):\n",
    "    print_images_line([image for image in sample(images, num)])\n",
    "\n",
    "def print_images_from_dir(path: str, num: int = 5):\n",
    "    print_images_line([imread(f\"{path}/{image}\") for image in sample(listdir(path), num)])\n",
    "\n",
    "def naturalize_urls(urls: list[str]) -> list[str]:\n",
    "    return [url.replace(\"medium\", \"large\") for url in urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Use following links to access image sets:\n",
    "Random images available [here](https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv).\n",
    "It is a validation set of [OpenImages](https://storage.googleapis.com/openimages/web/index.html) dataset, but it contains enough images for hogweed classification.\n",
    "\n",
    "Plant images available [here](https://www.inaturalist.org/observations/export) after signing in iNaturalist.\n",
    "* Use this request `has[]=photos&quality_grade=any&identifications=any&iconic_taxa[]=Plantae&projects[]=leningrad-oblast-flora` to retrieve different plant images.\n",
    "* Use this request `has[]=photos&quality_grade=any&identifications=any&iconic_taxa[]=Plantae&taxon_id=499936` to retrieve hogweed images.\n",
    "\n",
    "Please make sure `.csv` files received using given requests and links are placed in `./datasets` directory before running the following cell, making sure:\n",
    "* The random image dataset file name should be `other.csv`.\n",
    "* The hogweed image dataset file name should be `hogweed.csv`.\n",
    "* The other plants image dataset file name should be `cetera.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, concat\n",
    "from imagehash import average_hash\n",
    "from os import makedirs, system\n",
    "from tqdm.notebook import tqdm\n",
    "from shutil import rmtree\n",
    "from requests import get\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def clear_path(path: str) -> str:\n",
    "    rmtree(path, ignore_errors=True)\n",
    "    makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def download_and_save(img_source: str, img_type: str, count: int, source: [str]):\n",
    "    print(f\"Downloading {img_type} images from {img_source}, {len(source)} images provided\")\n",
    "    img_hashes = set()\n",
    "    img_code = 0\n",
    "\n",
    "    with tqdm(total=count, desc=\"Downloading\", unit=\"img\") as bar:\n",
    "        while len(img_hashes) < count:\n",
    "            if img_code >= len(source):\n",
    "                raise RuntimeError(f\"The source set contains only {len(source)} elements, {img_code}th was requested! ({img_code + 1 - count} collisions)\")\n",
    "            else:\n",
    "                try:\n",
    "                    img_data = Image.open(BytesIO(get(source[img_code]).content))\n",
    "                    img_hash = average_hash(img_data, hash_size=32)\n",
    "                    if img_hash not in img_hashes and len(img_data.getdata()) > 0:\n",
    "                        img_data.save(f\"{IMAGE_DIR}/{img_type}/{img_type}{img_code}.jpg\")\n",
    "                        img_hashes.add(img_hash)\n",
    "                        bar.update()\n",
    "                finally:\n",
    "                    img_code += 1\n",
    "                    continue\n",
    "\n",
    "    print(f\"Downloaded {img_code + 1} images finished, {img_code + 1 - count} collisions or wrong images found\")\n",
    "    print(f\"{img_source} dataset {img_type} image samples:\")\n",
    "    print_images_from_dir(f\"{IMAGE_DIR}/{img_type}\")\n",
    "\n",
    "\n",
    "print(f\"Train set should contain hogweed, cetera and other images, {IMAGES} of each kind\")\n",
    "\n",
    "print(\"Preparing directories\")\n",
    "clear_path(f\"{IMAGE_DIR}/hogweed\")\n",
    "clear_path(f\"{IMAGE_DIR}/cetera\")\n",
    "clear_path(f\"{IMAGE_DIR}/other\")\n",
    "\n",
    "frame = read_csv(\"./datasets/hogweed.csv\")\n",
    "open_frame = frame[frame[\"license\"] == \"CC0\"][\"image_url\"]\n",
    "frame = concat([frame[frame[\"license\"] != \"CC0\"][\"image_url\"], open_frame.head(len(open_frame) - 50)])\n",
    "download_and_save(\"iNaturalist\", \"hogweed\", IMAGES, naturalize_urls(frame.to_list()))\n",
    "\n",
    "frame = read_csv(\"./datasets/cetera.csv\")\n",
    "open_frame = frame[(frame[\"license\"] == \"CC0\") & (frame[\"scientific_name\"] != \"Heracleum sosnowskyi\")][\"image_url\"]\n",
    "frame = concat([frame[(frame[\"license\"] != \"CC0\") & (frame[\"scientific_name\"] != \"Heracleum sosnowskyi\")][\"image_url\"], open_frame.head(len(open_frame) - 50)])\n",
    "download_and_save(\"iNaturalist\", \"cetera\", IMAGES, naturalize_urls(frame.to_list()))\n",
    "\n",
    "frame = read_csv(\"./datasets/other.csv\")\n",
    "download_and_save(\"OpenImages\", \"other\", IMAGES, frame[\"OriginalURL\"])\n",
    "\n",
    "print(\"Removing ipynb caches\")\n",
    "system(\"rm -rf `find -type d -name .ipynb_checkpoints`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this cell to regenerate `./datasets/test.csv` file\n",
    "It will contain 50 last open source from each plant dataset (cetera, hogweed) that were not in train nor in validation datasets + 50 open source images from [unsplash](https://unsplash.com/).\n",
    "It is not guaranteed that unsplash images will be unique, but it's the only clearly open source image source was found.\n",
    "\n",
    "The generated file may be used with result testing script (`./test.py`) as follows: `python test.py -n ./models/[YOUR MODEL FILE NAME].tflite -s ./datasets/test.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "\n",
    "\n",
    "frame = read_csv(\"./datasets/hogweed.csv\")\n",
    "hogweed_frame = frame[frame[\"license\"] == \"CC0\"].tail(50)[\"image_url\"]\n",
    "frame = read_csv(\"./datasets/cetera.csv\")\n",
    "cetera_frame = frame[(frame[\"scientific_name\"] != \"Heracleum sosnowskyi\") & (frame[\"license\"] == \"CC0\")].tail(50)[\"image_url\"]\n",
    "\n",
    "URLs = naturalize_urls(hogweed_frame.to_list()) + naturalize_urls(cetera_frame.to_list()) + [f\"https://source.unsplash.com/random?sig={num}\" for num in range(50)]\n",
    "classes = sum([[cls] * 50 for cls in CLASS_NAMES], [])\n",
    "DataFrame(list(zip(classes, URLs)), columns=['class', 'url']).to_csv(path_or_buf=\"./datasets/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image dataset creation, splitting in train and validation datasets\n",
    "**NB!** in the first line `from tensorflow.python.keras.layers import RandomFlip, RandomRotation` causes [error](https://github.com/keras-team/keras/issues/15699) in model saving in current TensorFlow latest version (2.7) - it is an unexpected behavior, should be fixed in nearest future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "0_H_k8Xkv1Lv",
    "outputId": "bbe82398-4d27-4f46-df28-144230c35f85",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import RandomFlip, RandomRotation\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "from tensorflow.python.data import AUTOTUNE\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "\n",
    "dataset = image_dataset_from_directory(IMAGE_DIR, class_names=CLASS_NAMES, label_mode='categorical', batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
    "batches_num = dataset.cardinality()\n",
    "\n",
    "train_power = batches_num * 9 // 10\n",
    "train_dataset = dataset.take(train_power).prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = dataset.skip(train_power).take(train_power // 9).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "data_augmentation = Sequential([\n",
    "    RandomFlip('horizontal'),\n",
    "    RandomRotation(0.1)\n",
    "])\n",
    "\n",
    "print(f\"Train set has {train_dataset.cardinality()} batches, validation set has {validation_dataset.cardinality()} batches; train set will be augmented:\")\n",
    "for i in range(0, 5):\n",
    "    imgs = []\n",
    "    for img, _ in train_dataset.skip(i).take(1):\n",
    "        for j in range(0, 5):\n",
    "            imgs += [data_augmentation(expand_dims(img[0], 0))[0] / 255]\n",
    "    print_images_line(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization and compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import preprocess_input, Xception\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "\n",
    "INPUT_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "base_model = Xception(input_shape=INPUT_SHAPE, pooling='avg', include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = Input(shape=INPUT_SHAPE, name=\"re_shaper\")\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = Dropout(0.2, name=\"dropout\")(x)\n",
    "outputs = Dense(3, name=\"predictor\")(x)\n",
    "model = Model(inputs, outputs, name=\"hogweed_detector\")\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=Adam(learning_rate=base_learning_rate), loss=CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training top layers of the model (its 'head')\n",
    "Early stopping is used to prevent overfitting, usually it stops after 12-14 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "print(f\"Training model with {len(model.trainable_variables)} variables enabled.\")\n",
    "callbacks = [LoggingCallback(), EarlyStopping(patience=1, restore_best_weights=True, monitor='val_accuracy', min_delta=EARLY_STOPPING)]\n",
    "history = model.fit(train_dataset, epochs=INITIAL_EPOCHS, validation_data=validation_dataset, verbose=0, callbacks=callbacks)\n",
    "\n",
    "epochs = len(history.history['val_accuracy'])\n",
    "if epochs < INITIAL_EPOCHS:\n",
    "    print(f\"Training stopped early with validation accuracy {round(history.history['val_accuracy'][-1], 3)} after {epochs} epochs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preparing for fine-tuning\n",
    "Only top 80% of layers get fine-tuned not to mess up with base image detection weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "fine_tune_from = len(base_model.layers) // 5\n",
    "base_model.trainable = True\n",
    "for index, layer in enumerate(base_model.layers):\n",
    "    if index < fine_tune_from or type(layer) == BatchNormalization:\n",
    "        layer.trainable = False\n",
    "\n",
    "further_learning_rate = 0.00001\n",
    "model.compile(optimizer=RMSprop(learning_rate=further_learning_rate), loss=CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training middle and top layers of the model (fine-tuning)\n",
    "Early stopping is used to prevent overfitting, usually it stops after 1-2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "print(f\"Training model with {len(model.trainable_variables)} variables enabled.\")\n",
    "start_epoch = history.epoch[-1]\n",
    "callbacks = [LoggingCallback(), EarlyStopping(patience=1, restore_best_weights=True, monitor='val_accuracy', min_delta=EARLY_STOPPING)]\n",
    "history = model.fit(train_dataset, epochs=INITIAL_EPOCHS + FINE_TUNING_EPOCHS, validation_data=validation_dataset, initial_epoch=start_epoch, verbose=0, callbacks=callbacks)\n",
    "\n",
    "epochs = len(history.history['val_accuracy'])\n",
    "if epochs < start_epoch + FINE_TUNING_EPOCHS:\n",
    "    print(f\"Training stopped early with validation accuracy {round(history.history['val_accuracy'][-1], 3)} after {epochs} epochs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model\n",
    "Model is saved in both `.h5` and `.tflite` formats for mobile use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "f4484594730242f1966a701aba563294",
      "9741045a24674180a1d15ff96889d80c",
      "9288a4f9a3ff4540a2d94460e5a1ccc1",
      "2266db66cd4d44c3bc78c509dc1b4559",
      "a1c37a6d1eed49a18519a7d9dc15834d",
      "2be62d2e126143b7a6fd47543709397c",
      "35ab3c70478c447d852b6114b005b6b8",
      "3be3c730f3874089a7daa376b9edf993",
      "a76565a39a384e718ff3d4d06d2b72b5",
      "4acad93d1f8c43b18565c452f6f7957c",
      "f583ff3649d248bbbb4686bf4d084879"
     ]
    },
    "id": "opRLr_aov1Ly",
    "outputId": "2a18f3c1-6fe8-4cf8-a5de-e8c24dd03cfb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import lite\n",
    "from os import makedirs\n",
    "\n",
    "\n",
    "model_name = f\"hogweed_detector-{round(history.history['accuracy'][-1], 5)}\"\n",
    "\n",
    "makedirs(MODEL_DIR, exist_ok=True)\n",
    "model.save(f\"{MODEL_DIR}/{model_name}.h5\")\n",
    "with open(f\"{MODEL_DIR}/{model_name}.tflite\", 'wb') as file:\n",
    "    lite_model = lite.TFLiteConverter.from_keras_model(model).convert()\n",
    "    file.write(lite_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
